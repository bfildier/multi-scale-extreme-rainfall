##############################################################################
#                                                                            #
#    Benjamin Fildier, June 2017.                                            #
#                                                                            #
#    This script extract, from SPCAM hourly outputs, the daily mean mass     #
#    flux in the I50 and complementary CRM regions, CRM_MF_IXX and           #
#    CRM_MFdry_IXX for a given experiment name, input directory and time     #
#    boundaries. It reads the CRM points of XX% largest precipitation        #
#    rates and the corresponding vertical pressure profile, and computes     #
#    the mean MF over these points within each GCM cell.                               #
#                                                                            #
#    Prerequisites : outputdir/I${fraction} file previously generated by     #
#                        script getDailyCRMIndAbovePrecFraction.py           #
#                    varid has to have vertical dimension                    #
#    Arguments     : varid fraction experiment case datetime1 datetime2      #
#                        inputdir                                            #
#    Output file   : CRM-MF(dry)-I${fraction}_1hr_CESM111-SPCAM20_...        #
#                     ...${experiment}_r1i1p1_${datetime1}-${datetime2}.nc   #
#                                                                            #
##############################################################################


###--- Modules ---###
import glob
import sys,os
from netCDF4 import Dataset
from datetime import datetime
import numpy as np
import warnings
import socket

currentpath = os.path.dirname(os.path.realpath(__file__))
sys.path.insert(0,currentpath[:currentpath.rfind('/')+1]+'functions')

###--- Functions ---###

## Check we get correct arguments and return the tuple:
## (fraction, experiment, case, datetime1, datetime2, list of inputdir/*.nc files)
def parseArguments():
	args = sys.argv[1:]
	# Check number of arguments
	if len(args) != 6:
		print "Wrong number of arguments.\nRequired arguments: fraction "+\
		"experiment case datetime1 datetime2 inputdir"
		sys.exit(1)
	# Get list of files in directory (3rd argument)
	fraction, experiment, case, datetime1, datetime2 = args[:5]
	# Get time boundaries
	dt_bnds = []
	for tstamp in [datetime1,datetime2]:
		dt_info = [int(s) for s in tstamp.split('-') if s.isdigit()]
		dt_bnds.append(datetime(dt_info[0],dt_info[1],dt_info[2],dt_info[3]/3600))
	# Change date format to CMIP5 standard
	datetime1 = dt_bnds[0].isoformat().replace('-','').replace('T','').replace(':','')[:-2]
	datetime2 = dt_bnds[1].isoformat().replace('-','').replace('T','').replace(':','')[:-2]
	# Store correct files (between time boundaries, with correct case name)
	ncfiles = []
	for file in glob.glob(args[-1]+'/*.nc'):
		filename = os.path.basename(file)
		dt_info = [int(s) for s in filename.split('.')[3].split('-') if s.isdigit()]
		dt = datetime(dt_info[0],dt_info[1],dt_info[2],dt_info[3]/3600)
		if case in filename and ".cam.h0." in filename:
			if dt <= dt_bnds[1] and dt >= dt_bnds[0]:
				ncfiles.append(file)
	# Exit if no interesting files are found
	if len(ncfiles) == 0:
		print "No files matching request."
		sys.exit(0)
	ncfiles.sort()
	return int(fraction), experiment, case, datetime1, datetime2, ncfiles

def getInputDirectories(dataroot,compset,experiment):

	hostname = socket.gethostname()
	case = "bf_%s_%s"%(compset,experiment)
	if hostname == "jollyjumper":
		inputdir = os.path.join(dataroot,"simulations",case)
		inputdir_processed_day = os.path.join(dataroot,'preprocessed',case,'day')
		inputdir_processed_1hr = os.path.join(dataroot,'preprocessed',case,'1hr')
	elif "edison" in hostname:
		inputdir = os.path.join(dataroot,'archive',case,"atm/hist")
		inputdir_processed_day = os.path.join(os.path.dirname(currentpath),'preprocessed',
			case,'day')
		inputdir_processed_1hr = os.path.join(os.path.dirname(currentpath),'preprocessed',
			case,'1hr')
	inputdir_results = os.path.join(os.path.dirname(currentpath),'results')
	inputdir_fx = os.path.join(dataroot,'preprocessed/allExperiments/fx')

	return inputdir, inputdir_processed_day, inputdir_processed_1hr,\
		inputdir_results, inputdir_fx

def defineOutputDirectory(dataroot,compset,experiment):

	hostname = socket.gethostname()
	case = "bf_%s_%s"%(compset,experiment)
	if hostname == "jollyjumper":
		outputdir = os.path.join(os.path.dirname(os.path.dirname(inputdir)),
			'preprocessed',case,'day')
	elif "edison" in hostname:
		outputdir = os.path.join(os.path.dirname(currentpath),'preprocessed',case,'day')

	return outputdir

def getSubset(subsetName,inputdir_fx,experiment=None):

	landfile = 'landmask_fx_CESM111-SPCAM20_allExperiments_r0i0p0.nc'
	fh_landmask = Dataset(os.path.join(inputdir_fx,landfile))
	landmask = fh_landmask.variables['landmask']

	if subsetName == "ocean":
		# Define subset of points over ocean
		subset_pts = np.logical_not(landmask)
		fh_landmask.close()
	elif subsetName == "land":
		# Define subset of points over land
		subset_pts = np.array(landmask[:],dtype=bool)
		fh_landmask.close()
	elif subsetName == "tropics":
		subset_pts = np.ones(landmask.shape,dtype=bool)
	elif subsetName == "mfzero":
		# mfzero_file = 'MFZERO_day_CESM111-SPCAM20_'+experiment+'_r1i1p1_18500501-18500502.nc'
		mfzero_file = 'MFZERO_day_CESM111-SPCAM20_'+experiment+'_r1i1p1_18500501-18510430.nc'
		fh_mfzero = Dataset(os.path.join(os.path.dirname(inputdir_fx),'day',mfzero_file))
		mfzero = fh_mfzero.variables['MFZERO']
		subset_pts = np.array(mfzero[:],dtype=bool)
		fh_mfzero.close()

	return subset_pts


###--- Main program ---###

if __name__ == '__main__':

##-- Get arguments --##

	fraction, experiment, case, datetime1, datetime2, ncfiles = parseArguments()
	newvaridwet = "CRM_MF_I%d"%fraction
	newvariddry = "CRM_MFdry_I%d"%fraction
	indvarid = "I%d"%fraction

##-- Set directories --##

	#- Directories -#
	inputdir, inputdir_processed_day, inputdir_processed_1hr, inputdir_results,\
		inputdir_fx = getInputDirectories(dataroot,compset,experiment)
	outputdir = defineOutputDirectory(dataroot,compset,experiment)

	#- Output files-#
	outputfile_wet = newvaridwet.replace('_','-')+"_day_CESM111-SPCAM20_"+experiment+\
	"_r1i1p1_"+datetime1[:8]+'-'+datetime2[:8]+".nc"
	outputfile_dry = newvariddry.replace('_','-')+"_day_CESM111-SPCAM20_"+experiment+\
	"_r1i1p1_"+datetime1[:8]+'-'+datetime2[:8]+".nc"

	# #- Input file -#
	# indfile = indvarid.replace('_','-')+"_1hr_CESM111-SPCAM20_"+experiment+\
	# "_r1i1p1_"+datetime1+'-'+datetime2+".nc"


##-- Load required physical variables -- ##
	
	w_id = "CRM_W"
	spechum_id = 'Q'
	temp_id = 'T'
	pressurf_id = 'PS'
	pw_id = 'CRM_QPC'
	# Load all variables
	w_vals = getSimulationValues(w_id,inputdir,dates=(datetime1,datetime2))
	spechum_vals = getSimulationValues(spechum_id,inputdir,dates=(datetime1,datetime2))
	temp_vals = getSimulationValues(temp_id,inputdir,dates=(datetime1,datetime2))
	pressurf_vals = getSimulationValues(pressurf_id,inputdir,dates=(datetime1,datetime2))
	pw_vals = getSimulationValues(pw_id,inputdir,dates=(datetime1,datetime2))
	# Reduce latitude dimension
	nlat = pressurf_vals.shape[-2]
	lat_slice = slice(nlat/3,2*nlat/3)
	w_vals = w_vals[:,:,:,:,lat_slice,:]
	spechum_vals = spechum_vals[:,:,lat_slice,:]
	temp_vals = temp_vals[:,:,lat_slice,:]
	pressurf_vals = pressurf_vals[:,lat_slice,:]
	pw_vals = pw_vals[:,:,:,:,lat_slice,:]

##-- Load required index information --##

	# IXX indices
	I_vals = getVar(area_id,inputdir_processed_1hr,dates=(datetime1,datetime2))
	I_vals = 1-I_vals

##-- Load computeP and subset --##

	lev_file = 'lev_fx_CESM111-SPCAM20_allExperiments_r0i0p0.nc'
	computeP = getPressureCoordinateFunction(os.path.join(inputdir_fx,lev_file))
	subset = getSubset(subsetName,inputdir_fx,experiment=experiment)

##-- Create output files --##

	fh_source = Dataset(ncfiles[0],'r')
	lon_source = fh_source.variables['lon']
	lat_source = fh_source.variables['lat']
	vardims = fh_source.variables[pressurf_id].dimensions
	varshape = fh_source.variables[pressurf_id].shape
	nlev = varshape[1]

	#- Create files -#
	rootgrp_wet = Dataset(os.path.join(outputdir,outputfile_wet),'w')
	rootgrp_dry = Dataset(os.path.join(outputdir,outputfile_dry),'w')

	#- Create dimensions and global attributes -#
	nlon = len(lon_source)
	rootgrp_wet.createDimension("lon",nlon)
	rootgrp_dry.createDimension("lon",nlon)
	nlat = len(lat_source)
	lat_slice = slice(nlat/3,2*nlat/3)
	rootgrp_wet.createDimension("lat",nlat/3)
	rootgrp_dry.createDimension("lat",nlat/3)
	rootgrp_wet.createDimension("time",None)
	rootgrp_dry.createDimension("time",None)
	rootgrp_wet.case = str(fh_source.case)
	rootgrp_dry.case = str(fh_source.case)
	rootgrp_wet.description = "CRM-level mass flux averaged over points contributing to the"+\
	" most intense "+str(fraction)+"%% CRM_PREC values in the CESM111-SPCAM20 "+\
	experiment+" AMIP experiment."
	rootgrp_dry.description = "CRM-level mass flux averaged over points contributing to the"+\
	" most intense "+str(fraction)+"%% CRM_PREC values in the CESM111-SPCAM20 "+\
	experiment+" AMIP experiment."

	#- Define variables -#
	lon_wet = rootgrp_wet.createVariable("lon","f8",("lon",))
	lon_wet[:] = lon_source[:]
	lon_dry = rootgrp_dry.createVariable("lon","f8",("lon",))
	lon_dry[:] = lon_source[:]
	lat_wet = rootgrp_wet.createVariable("lat","f8",("lat",))
	lat_wet[:] = lat_source[lat_slice]
	lat_dry = rootgrp_dry.createVariable("lat","f8",("lat",))
	lat_dry[:] = lat_source[lat_slice]
	time_wet = rootgrp_wet.createVariable("time","f8",("time",))
	date_wet = rootgrp_wet.createVariable("date","i4",("time",))
	datesec_wet = rootgrp_wet.createVariable("datesec","i4",("time",))
	newvar_wet = rootgrp_wet.createVariable(newvaridwet,"f4",("time","lat","lon"))
	time_dry = rootgrp_dry.createVariable("time","f8",("time",))
	date_dry = rootgrp_dry.createVariable("date","i4",("time",))
	datesec_dry = rootgrp_dry.createVariable("datesec","i4",("time",))
	newvar_dry = rootgrp_dry.createVariable(newvariddry,"f4",("time","lat","lon"))
	
	#- Define variable attributes -#
	lon_wet.long_name = lon_dry.long_name = str(lon_source.long_name)
	lat_wet.long_name = lat_dry.long_name = str(lat_source.long_name)
	date_wet.long_name = date_dry.long_name = str(fh_source.variables['date'].long_name)
	datesec_wet.long_name = datesec_dry.long_name = str(fh_source.variables['datesec'].long_name)
	lon_wet.units = lon_dry.units = str(lon_source.units)
	lat_wet.units = lat_dry.units = str(lat_source.units)
	time_wet.units = time_dry.units = str(fh_source.variables['time'].units)
	time_wet.calendar = time_dry.calendar = str(fh_source.variables['time'].calendar)
	newvar_wet.long_name = newvar_dry.long_name = str(fh_source.variables[varid].long_name)
	newvar_wet.units = newvar_dry.units = str(fh_source.variables[varid].units)

	fh_source.close()

##-- Read all files --##

	n = len(ncfiles)
	time_values = np.zeros((n,))
	date_values = np.zeros((n,))
	datesec_values = np.zeros((n,))
	var_values = np.zeros((n,varshape[1],varshape[2],nlat/3,nlon))

	# Start chronometer
	t0 = datetime.now()

	# Initialize
	newvar_values_wet = np.zeros((1,nlat/3,nlon))
	newvar_values_dry = np.zeros((1,nlat/3,nlon))
	
	# Compute values
	for ilat in range(nlat/3):
		for ilon in range(nlon):

			crm_mf_wet = []
			crm_mf_dry = []
			# Get the CRM points that correspond to the convective event
			I_wet = np.array(I_vals[...,ilat,ilon] == 1,dtype=bool).squeeze()
			for itime,ix in zip(*np.where(I_wet)):
				# Compute and store CRM mass flux at current CRM point
				pressurf = pressurf_vals[itime,ilat,ilon]
				pres = computeP(pressurf)
				spechum = spechum_vals[itime,:,ilat,ilon]
				temp = temp_vals[itime,:,ilat,ilon]
				rho = airDensity(temp,pres,spechum)
				wspeed = w_vals[itime,...,ix,ilat,ilon].squeeze()
				pw = pw_vals[itime,...,ix,ilat,ilon].squeeze()
				omega = np.multiply(wspeed,-g*rho)
				crm_mf_wet.append(verticalPressureIntegral(pres,omega) / verticalPressureIntegral(pres))
			newvar_values_wet[0,ilat,ilon] = np.nanmean(np.array(crm_mf_wet))
			
			# Get the CRM points outside the convective event
			I_dry = np.array(I_vals[...,ilat,ilon] == 1,dtype=bool).squeeze()
			for itime,ix in zip(*np.where(I_dry)):
				# Compute and store CRM mass flux at current CRM point
				pressurf = pressurf_vals[itime,ilat,ilon]
				pres = computeP(pressurf)
				spechum = spechum_vals[itime,:,ilat,ilon]
				temp = temp_vals[itime,:,ilat,ilon]
				rho = airDensity(temp,pres,spechum)
				wspeed = w_vals[itime,...,ix,ilat,ilon].squeeze()
				pw = pw_vals[itime,...,ix,ilat,ilon].squeeze()
				omega = np.multiply(wspeed,-g*rho)
				crm_mf_dry.append(verticalPressureIntegral(pres,omega) / verticalPressureIntegral(pres))
			newvar_values_dry[0,ilat,ilon] = np.nanmean(np.array(crm_mf_dry))

			# with warnings.catch_warnings():
			# 	warnings.simplefilter("ignore", category=RuntimeWarning)
			# 	newvar_values_wet[0,ilat,ilon] = np.nanmean(values_ok_wet)
			# 	newvar_values_dry[0,ilat,ilon] = np.nanmean(values_ok_dry)

	# Stop chronometer
	t1 = datetime.now()

	print
	print "------ It took", (t1-t0), "to process %d files."%n

##-- Write to output --##

	time_wet[:] = time_dry[:] = time_values[:].mean()
	date_wet[:] = date_dry[:] = date_values[0]
	datesec_wet[:] = datesec_dry[:] = datesec_values[:].mean()
	newvar_wet[:] = newvar_values_wet[:]
	newvar_dry[:] = newvar_values_dry[:]

	rootgrp_wet.close()
	rootgrp_dry.close()

	sys.exit(0)







