##############################################################################
#                                                                            #
#    Benjamin Fildier, August 2017.                                          #
#                                                                            #
#    This script extract, from SPCAM hourly outputs, values for varid V      #
#    for a given experiment name, input directory and time boundaries. It    #
#    reads the CRM points of XX% largest precipitation rates and computes    #
#    the mean of V outside these points within each GCM cell.                #
#                                                                            #
#    Output variable: V_IXX (e.g. V_I90 for the most intense 90% rainy       #
#    points).                                                                #
#                                                                            #
#    Prerequisites : outputdir/I${fraction} file previously generated by     #
#                        script getDailyCRMIndAbovePrecFraction.py           #
#                    varid has to have vertical dimension                    #
#    Arguments     : varid fraction experiment case datetime1 datetime2      #
#                        inputdir                                            #
#    Output file   : ${varid}-I${fraction}_1hr_CESM111-SPCAM20_...           #
#                     ...${experiment}_r1i1p1_${datetime1}-${datetime2}.nc   #
#                                                                            #
##############################################################################


###--- Modules ---###
import glob
import sys,os
from netCDF4 import Dataset
from datetime import datetime
import numpy as np
import warnings
import socket


###--- Functions ---###

## Check we get correct arguments and return the tuple:
## (fraction, experiment, case, datetime1, datetime2, list of inputdir/*.nc files)
def parseArguments():
	args = sys.argv[1:]
	# Check number of arguments
	if len(args) != 7:
		print "Wrong number of arguments.\nRequired arguments: varid fraction"+\
		"experiment case datetime1 datetime2 inputdir"
		sys.exit(1)
	# Get list of files in directory (3rd argument)
	varid, fraction, experiment, case, datetime1, datetime2 = args[:6]
	# Get time boundaries
	dt_bnds = []
	for tstamp in [datetime1,datetime2]:
		dt_info = [int(s) for s in tstamp.split('-') if s.isdigit()]
		dt_bnds.append(datetime(dt_info[0],dt_info[1],dt_info[2],dt_info[3]/3600))
	# Change date format to CMIP5 standard
	datetime1 = dt_bnds[0].isoformat().replace('-','').replace('T','').replace(':','')[:-2]
	datetime2 = dt_bnds[1].isoformat().replace('-','').replace('T','').replace(':','')[:-2]
	# Store correct files (between time boundaries, with correct case name)
	ncfiles = []
	for file in glob.glob(args[-1]+'/*.nc'):
		filename = os.path.basename(file)
		if case in filename and ".cam.h0." in filename:
			dt_info = [int(s) for s in filename.split('.')[3].split('-') if s.isdigit()]
			dt = datetime(dt_info[0],dt_info[1],dt_info[2],dt_info[3]/3600)
			if dt <= dt_bnds[1] and dt >= dt_bnds[0]:
				ncfiles.append(file)
	# Exit if no interesting files are found
	if len(ncfiles) == 0:
		print "No files matching request."
		sys.exit(0)
	ncfiles.sort()
	return varid, int(fraction), experiment, case, datetime1, datetime2, ncfiles


###--- Main program ---###

if __name__ == '__main__':

	##-- Get arguments --##

	varid, fraction, experiment, case, datetime1, datetime2, ncfiles = parseArguments()
	areaid = "O%d"%fraction
	newvarid = varid+"_%s"%areaid
	indvarid = "I%d"%fraction

	##-- Define input, output variables --##

	currentpath = os.path.dirname(os.path.realpath(__file__))
	inputdir = os.path.dirname(ncfiles[0])
	hostname = socket.gethostname()
	if hostname == "jollyjumper":
		outputdir = os.path.join(os.path.dirname(os.path.dirname(inputdir)),
			'preprocessed',case,'day')
	elif "edison" in hostname or "cori" in hostname:
		outputdir = os.path.join(os.path.dirname(currentpath),'preprocessed',case,'day')
	outputfile = newvarid.replace('_','-')+"_day_CESM111-SPCAM20_"+experiment+\
	"_r1i1p1_"+datetime1[:8]+'-'+datetime2[:8]+".nc"
	inddir = os.path.join(os.path.dirname(outputdir),'1hr')
	indfile = indvarid.replace('_','-')+"_1hr_CESM111-SPCAM20_"+experiment+\
	"_r1i1p1_"+datetime1+'-'+datetime2+".nc"

	print "outputdir :", outputdir
	print "outputfile:", outputfile
	print "inddir    :", inddir
	print "indfile   :", indfile

	##-- Create output file --##

	fh_source = Dataset(ncfiles[0],'r')
	lon_source = fh_source.variables['lon']
	lat_source = fh_source.variables['lat']
	vardims = fh_source.variables[varid].dimensions
	vert = "crm_nz" in vardims
	varshape = fh_source.variables[varid].shape
	nlev = varshape[1]
	# Create file
	rootgrp = Dataset(os.path.join(outputdir,outputfile),'w')

	#- Create dimensions and global attributes -#
	nlon = len(lon_source)
	rootgrp.createDimension("lon",nlon)
	nlat = len(lat_source)
	lat_slice = slice(nlat/3,2*nlat/3)
	rootgrp.createDimension("lat",nlat/3)
	if vert:
		rootgrp.createDimension("lev",nlev)
	rootgrp.createDimension("time",None)
	rootgrp.case = str(fh_source.case)
	rootgrp.description = "CRM mean values over points not contributing to the"+\
	" most intense "+str(fraction)+"%% CRM_PREC values in the CESM111-SPCAM20 "+\
	experiment+" AMIP experiment."

	#- Define variables -#
	lon = rootgrp.createVariable("lon","f8",("lon",))
	lon[:] = lon_source[:]
	lat = rootgrp.createVariable("lat","f8",("lat",))
	lat[:] = lat_source[lat_slice]
	time = rootgrp.createVariable("time","f8",("time",))
	date = rootgrp.createVariable("date","i4",("time",))
	datesec = rootgrp.createVariable("datesec","i4",("time",))
	if vert:
		newvar = rootgrp.createVariable(newvarid,"f4",("time","lev","lat","lon"))
	else:
		newvar = rootgrp.createVariable(newvarid,"f4",("time","lat","lon"))

	#- Define variable attributes -#
	lon.long_name = str(lon_source.long_name)
	lat.long_name = str(lat_source.long_name)
	date.long_name = str(fh_source.variables['date'].long_name)
	datesec.long_name = str(fh_source.variables['datesec'].long_name)
	lon.units = str(lon_source.units)
	lat.units = str(lat_source.units)
	time.units = str(fh_source.variables['time'].units)
	time.calendar = str(fh_source.variables['time'].calendar)
	newvar.long_name = str(fh_source.variables[varid].long_name)
	newvar.units = str(fh_source.variables[varid].units)

	fh_source.close()

	##-- Read all files --##

	n = len(ncfiles)
	time_values = np.zeros((n,))
	date_values = np.zeros((n,))
	datesec_values = np.zeros((n,))
	if vert:
		var_values = np.zeros((n,varshape[1],varshape[2],varshape[3],nlat/3,nlon))
	else:
		var_values = np.zeros((n,varshape[1],varshape[2],nlat/3,nlon))

	# Start chronometer
	t0 = datetime.now()

	# Read in all varid values
	for i in range(n):

		ncfile = ncfiles[i]
		print "... Opening "+ncfile.split('.')[3]+" data ..."
		# Open file
		fh = Dataset(ncfile)
		# Copy values
		time_values[i] = fh.variables['time'][:]
		date_values[i] = fh.variables['date'][:]
		datesec_values[i] = fh.variables['datesec'][:]
		if vert:
			var_values[i] = fh.variables[varid][:,:,:,:,lat_slice,:]
		else:
			var_values[i] = fh.variables[varid][:,:,:,lat_slice,:]
		# Close file
		fh.close()

	# Open indvarid file
	fh_ind = Dataset(os.path.join(inddir,indfile),'r')
	ind_values = np.logical_not(np.array(fh_ind.variables[indvarid][:],dtype=bool))

	# Initialize
	if vert:
		newvar_values = np.zeros((1,nlev,nlat/3,nlon))
	else:
		newvar_values = np.zeros((1,nlat/3,nlon))
	# Compute values
	for ilat in range(nlat/3):
		for ilon in range(nlon):
			# Stack filter indices over nlevels, level dimension staying first
			ind = ind_values[:,:,:,ilat,ilon]
			if vert:
				ind4D = np.vstack([[ind]]*nlev)
				# Swap time and lev dimension in the data
				values = var_values[:,:,:,:,ilat,ilon].swapaxes(0,1)
				# Apply filter-indices to the values but retain vertical dimension
				values_ok = values[ind4D].reshape(nlev,ind4D.sum()/nlev)
				with warnings.catch_warnings():
					warnings.simplefilter("ignore", category=RuntimeWarning)
					newvar_values[0,:,ilat,ilon] = values_ok.mean(axis=1)
			else:
				values_ok = var_values[:,:,:,ilat,ilon]
				# with warnings.catch_warnings():
				# 	warnings.simplefilter("ignore", category=RuntimeWarning)
				# 	newvar_values[0,ilat,ilon] = values_ok[ind].mean()
				if ind.sum() > 0 :
					newvar_values[0,ilat,ilon] = values_ok[ind].mean()
	
	# Replace Nans with -1 flags
	# newvar_values[np.isnan(newvar_values)] = -1

	# Stop chronometer
	t1 = datetime.now()

	print
	print "------ It took", (t1-t0), "to process %d files."%n

	##-- Write to output --##

	time[:] = time_values[:].mean()
	date[:] = date_values[0]
	datesec[:] = datesec_values[:].mean()
	newvar[:] = newvar_values[:]

	rootgrp.close()

	sys.exit(0)






